{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import onnx\n",
    "import onnxruntime\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST('..', train=True, download=True)\n",
    "test_data = datasets.MNIST('..', train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot image\n",
    "def mnist_plt(img):\n",
    "    if len(img) == 2:\n",
    "        label = img[1]\n",
    "        img = img[0]\n",
    "        print(f\"label: {label}\")\n",
    "        \n",
    "    img = np.matrix(img)\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def ascii_plot(img, char=\" \", outer=\"X\"):\n",
    "    for row in img:\n",
    "        for pixel in row:\n",
    "            if pixel > .5:\n",
    "                print(char, end=\"\")\n",
    "            else:\n",
    "                print(outer, end=\"\")\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"C:/workspace/tenseal-inference/models/lenet-5_square.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    f_x = np.exp(x) / np.sum(np.exp(x))\n",
    "    return f_x\n",
    "\n",
    "def comparison(model_path, x, tenseal_result_path, plot=True):\n",
    "    if plot:\n",
    "        mnist_plt(x)\n",
    "    model = onnx.load(model_path)\n",
    "    session = onnxruntime.InferenceSession(model_path)\n",
    "    \n",
    "    y = session.run(None, {model.graph.input[0].name: x})[0][0]\n",
    "    \n",
    "    sy = softmax(y)\n",
    "    \n",
    "    print(f\"cleartext onnxruntime: {np.argmax(y)}\")\n",
    "    for i,yi in enumerate(y):\n",
    "        print(f\"{i} {yi:+10.6f} {sy[i]:.4f}\")\n",
    "    print()\n",
    "\n",
    "    ## tenseal-inference result\n",
    "    with open(tenseal_result_path, 'rb') as f:\n",
    "        a = np.load(f)\n",
    "\n",
    "    sa = softmax(a)\n",
    "        \n",
    "    print(f\"tenseal-inference: {np.argmax(a)}\")\n",
    "    for i,ai in enumerate(a):\n",
    "        print(i, f\"{ai:+#10.6f} {sa[i]:.4f}\")\n",
    "    print()\n",
    "\n",
    "    # plt.bar(np.arange(10)-0.2, y, width=.4, label=\"clear\")\n",
    "    # plt.bar(np.arange(10)+0.2, a, width=.4, label=\"tenseal\")\n",
    "    # plt.grid()\n",
    "    # plt.legend()\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "\n",
    "data = test_data[index]\n",
    "x = np.array(data[0], dtype=np.float32).reshape(1,1,28,28) / 255\n",
    "tenseal_result_path = f\"../tenseal-inference/tmp/poster/result{index}.npy\"\n",
    "\n",
    "print(f\"Correct result: {data[1]}\")\n",
    "comparison(model_path, x, tenseal_result_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b081a66ee97bd2b6a16f43955f1d810b7ea816d6eaeb65e157ef9e038445f0c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
