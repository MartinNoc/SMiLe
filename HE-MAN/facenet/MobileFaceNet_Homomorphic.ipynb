{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.utils.data as data\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "class FaceFeatureExtractor(nn.Module):\n",
    "    def __init__(self, latent_c=256):\n",
    "        super(FaceFeatureExtractor, self).__init__()\n",
    "\n",
    "        # define layers\n",
    "        self.leaky_alpha = 0.1\n",
    "        self.conv_sep = nn.Conv2d(in_channels=128, out_channels=latent_c, kernel_size=(1,1), stride=(1,1), padding=(0,0), groups=1, bias=False)\n",
    "        self.bn_sep = nn.BatchNorm2d(latent_c)\n",
    "        # self.relu = nn.ReLU(latent_c)\n",
    "        self.lrelu = nn.LeakyReLU(negative_slope=self.leaky_alpha)\n",
    "        self.conv_dw = nn.Conv2d(latent_c, out_channels=latent_c, kernel_size=(7,7), stride=(1,1), padding=(0,0), groups=latent_c, bias=False)\n",
    "        self.bn_dw = nn.BatchNorm2d(latent_c)\n",
    "        self.conv_fin = nn.Conv2d(latent_c, out_channels=128, kernel_size=(1,1), stride=(1,1), padding=(0,0), groups=1, bias=False)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # init weights\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_sep(x)\n",
    "        x = self.bn_sep(x)\n",
    "        x = self.lrelu(x)\n",
    "        x = self.conv_dw(x)\n",
    "        x = self.bn_dw(x)\n",
    "        x = self.conv_fin(x)\n",
    "        return self.flatten(x)\n",
    "\n",
    "class LatentData(data.Dataset):\n",
    "    def __init__(self, path):\n",
    "        self.paths = np.load(os.path.join(path, \"paths.npy\"))\n",
    "        self.labels = np.load(os.path.join(path, \"labels.npy\"))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = np.load(self.paths[index]).squeeze()\n",
    "        label = self.labels[index]\n",
    "\n",
    "        return data, int(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "def l2_norm(input,axis=1):\n",
    "    norm = torch.norm(input,2,axis,True)\n",
    "    output = torch.div(input, norm)\n",
    "    return output\n",
    "\n",
    "class Arcface(nn.Module):\n",
    "    # implementation of additive margin softmax loss in https://arxiv.org/abs/1801.05599    \n",
    "    def __init__(self, embedding_size=128, classnum=51332,  s=64., m=0.5):\n",
    "        super(Arcface, self).__init__()\n",
    "        self.classnum = classnum\n",
    "        self.kernel = nn.Parameter(torch.Tensor(embedding_size,classnum))\n",
    "        nn.init.xavier_uniform_(self.kernel)\n",
    "        # initial kernel\n",
    "        self.kernel.data.uniform_(-1, 1).renorm_(2,1,1e-5).mul_(1e5)\n",
    "        self.m = m # the margin value, default is 0.5\n",
    "        self.s = s # scalar value default is 64, see normface https://arxiv.org/abs/1704.06369\n",
    "        self.cos_m = math.cos(m)\n",
    "        self.sin_m = math.sin(m)\n",
    "        self.mm = self.sin_m * m  # issue 1\n",
    "        self.threshold = math.cos(math.pi - m)\n",
    "    def forward(self, embbedings, label):\n",
    "        # weights norm\n",
    "        nB = len(embbedings)\n",
    "        kernel_norm = l2_norm(self.kernel,axis=0) # normalize for each column\n",
    "        # cos(theta+m)\n",
    "        cos_theta = torch.mm(embbedings,kernel_norm)\n",
    "#         output = torch.mm(embbedings,kernel_norm)\n",
    "        cos_theta = cos_theta.clamp(-1,1) # for numerical stability\n",
    "        cos_theta_2 = torch.pow(cos_theta, 2)\n",
    "        sin_theta_2 = 1 - cos_theta_2\n",
    "        sin_theta = torch.sqrt(sin_theta_2)\n",
    "        cos_theta_m = (cos_theta * self.cos_m - sin_theta * self.sin_m)\n",
    "        # this condition controls the theta+m should in range [0, pi]\n",
    "        #      0<=theta+m<=pi\n",
    "        #     -m<=theta<=pi-m\n",
    "        cond_v = cos_theta - self.threshold\n",
    "        cond_mask = cond_v <= 0\n",
    "        keep_val = (cos_theta - self.mm) # when theta not in [0,pi], use cosface instead\n",
    "        cos_theta_m[cond_mask] = keep_val[cond_mask]\n",
    "        output = cos_theta * 1.0 # a little bit hacky way to prevent in_place operation on cos_theta\n",
    "        idx_ = torch.arange(0, nB, dtype=torch.long)\n",
    "        output[idx_, label] = cos_theta_m[idx_, label]\n",
    "        output *= self.s # scale up in order to make softmax work, first introduced in normface\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/11, Iters: 000100, loss: 28.1051, train_accuracy: 0.0000, time: 1.09 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 000200, loss: 26.7360, train_accuracy: 0.0000, time: 1.01 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 000300, loss: 25.2333, train_accuracy: 0.0000, time: 1.05 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 000400, loss: 25.5040, train_accuracy: 0.0000, time: 1.17 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 000500, loss: 25.4533, train_accuracy: 0.0000, time: 1.26 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 000600, loss: 23.2878, train_accuracy: 0.0000, time: 1.27 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 000700, loss: 23.8006, train_accuracy: 0.0000, time: 1.35 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 000800, loss: 23.4216, train_accuracy: 0.0000, time: 1.41 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 000900, loss: 23.1530, train_accuracy: 0.0000, time: 1.17 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 001000, loss: 22.8171, train_accuracy: 0.0000, time: 1.44 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 001100, loss: 21.1549, train_accuracy: 0.0156, time: 1.39 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 001200, loss: 20.9940, train_accuracy: 0.0000, time: 1.40 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 001300, loss: 22.1820, train_accuracy: 0.0156, time: 1.38 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 001400, loss: 20.4836, train_accuracy: 0.0156, time: 1.29 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 001500, loss: 21.5224, train_accuracy: 0.0000, time: 1.19 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 001600, loss: 18.9709, train_accuracy: 0.0000, time: 1.18 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 001700, loss: 19.1186, train_accuracy: 0.0000, time: 1.38 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 001800, loss: 19.0514, train_accuracy: 0.0312, time: 1.38 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 001900, loss: 16.4589, train_accuracy: 0.0469, time: 1.38 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 002000, loss: 18.3899, train_accuracy: 0.0156, time: 1.41 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 002100, loss: 18.5967, train_accuracy: 0.0312, time: 1.25 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 002200, loss: 17.3487, train_accuracy: 0.0312, time: 1.17 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 002300, loss: 17.6224, train_accuracy: 0.0469, time: 1.26 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 002400, loss: 19.7369, train_accuracy: 0.0000, time: 1.40 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 002500, loss: 16.7641, train_accuracy: 0.0625, time: 1.42 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 002600, loss: 17.5402, train_accuracy: 0.0625, time: 1.39 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 002700, loss: 17.4905, train_accuracy: 0.0469, time: 1.36 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 002800, loss: 16.0728, train_accuracy: 0.0156, time: 1.14 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 002900, loss: 15.2315, train_accuracy: 0.0312, time: 1.19 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 003000, loss: 15.0846, train_accuracy: 0.0781, time: 1.23 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 003100, loss: 17.3305, train_accuracy: 0.0469, time: 1.40 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 003200, loss: 14.6354, train_accuracy: 0.0312, time: 1.48 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 003300, loss: 13.2808, train_accuracy: 0.0625, time: 1.41 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 003400, loss: 14.2345, train_accuracy: 0.0938, time: 1.38 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 003500, loss: 14.6069, train_accuracy: 0.0625, time: 1.15 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 003600, loss: 12.7980, train_accuracy: 0.0938, time: 1.16 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 003700, loss: 14.9988, train_accuracy: 0.0938, time: 1.30 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 003800, loss: 13.7003, train_accuracy: 0.1094, time: 1.45 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 003900, loss: 14.7572, train_accuracy: 0.0312, time: 1.44 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 004000, loss: 14.0677, train_accuracy: 0.0938, time: 1.42 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 004100, loss: 12.4638, train_accuracy: 0.1406, time: 1.40 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 004200, loss: 10.7934, train_accuracy: 0.1250, time: 1.18 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 004300, loss: 14.1961, train_accuracy: 0.0781, time: 1.17 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 004400, loss: 14.7639, train_accuracy: 0.1406, time: 1.36 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 004500, loss: 13.6564, train_accuracy: 0.1250, time: 1.42 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 004600, loss: 12.4051, train_accuracy: 0.1719, time: 1.13 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 004700, loss: 11.6459, train_accuracy: 0.1250, time: 1.09 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 004800, loss: 12.1048, train_accuracy: 0.1562, time: 1.17 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 004900, loss: 13.2904, train_accuracy: 0.1094, time: 1.07 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 005000, loss: 14.7403, train_accuracy: 0.0469, time: 1.08 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 005100, loss: 12.3917, train_accuracy: 0.0938, time: 1.06 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 005200, loss: 11.8756, train_accuracy: 0.1875, time: 1.19 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 005300, loss: 11.9396, train_accuracy: 0.0469, time: 1.28 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 005400, loss: 13.1381, train_accuracy: 0.0938, time: 1.30 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 005500, loss: 13.9054, train_accuracy: 0.0781, time: 1.32 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 005600, loss: 11.1833, train_accuracy: 0.1562, time: 1.40 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 005700, loss: 11.1482, train_accuracy: 0.1406, time: 1.15 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 005800, loss: 11.2599, train_accuracy: 0.0781, time: 1.19 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 005900, loss: 9.4035, train_accuracy: 0.2969, time: 1.36 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 006000, loss: 8.9340, train_accuracy: 0.1406, time: 1.37 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 006100, loss: 10.9657, train_accuracy: 0.0781, time: 1.33 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 006200, loss: 10.1534, train_accuracy: 0.1719, time: 1.07 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 006300, loss: 10.5716, train_accuracy: 0.1875, time: 1.13 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 006400, loss: 11.2200, train_accuracy: 0.0781, time: 1.15 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 006500, loss: 10.2739, train_accuracy: 0.2500, time: 1.03 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 006600, loss: 9.4970, train_accuracy: 0.1406, time: 1.10 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 006700, loss: 11.1210, train_accuracy: 0.1094, time: 1.22 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 006800, loss: 10.8172, train_accuracy: 0.1562, time: 1.33 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 006900, loss: 9.5434, train_accuracy: 0.1875, time: 1.24 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 007000, loss: 8.1654, train_accuracy: 0.2812, time: 1.06 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 007100, loss: 11.6936, train_accuracy: 0.1094, time: 1.17 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 007200, loss: 9.5301, train_accuracy: 0.0938, time: 1.15 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 007300, loss: 9.2955, train_accuracy: 0.1875, time: 1.08 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 007400, loss: 10.7073, train_accuracy: 0.1406, time: 1.14 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 007500, loss: 10.6568, train_accuracy: 0.1094, time: 1.23 s/iter, learning rate: 0.01\n",
      "Epoch 0/11, Iters: 007600, loss: 8.9713, train_accuracy: 0.2031, time: 1.34 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 007700, loss: 8.3279, train_accuracy: 0.2969, time: 0.26 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 007800, loss: 10.1210, train_accuracy: 0.1719, time: 0.97 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 007900, loss: 7.7095, train_accuracy: 0.1719, time: 0.94 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 008000, loss: 9.9114, train_accuracy: 0.1719, time: 0.99 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 008100, loss: 9.5966, train_accuracy: 0.1406, time: 0.85 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 008200, loss: 8.5830, train_accuracy: 0.1094, time: 0.97 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 008300, loss: 10.4480, train_accuracy: 0.1562, time: 1.00 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 008400, loss: 9.5943, train_accuracy: 0.1562, time: 1.00 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 008500, loss: 9.5052, train_accuracy: 0.2500, time: 0.82 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 008600, loss: 8.4576, train_accuracy: 0.2031, time: 0.82 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 008700, loss: 7.7832, train_accuracy: 0.2031, time: 0.76 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 008800, loss: 9.2817, train_accuracy: 0.1719, time: 0.82 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 008900, loss: 7.8763, train_accuracy: 0.1562, time: 0.78 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 009000, loss: 8.0494, train_accuracy: 0.1406, time: 0.79 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 009100, loss: 9.1260, train_accuracy: 0.2500, time: 0.85 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 009200, loss: 7.0304, train_accuracy: 0.2344, time: 0.83 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 009300, loss: 8.7289, train_accuracy: 0.1719, time: 0.93 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 009400, loss: 8.7985, train_accuracy: 0.1562, time: 1.06 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 009500, loss: 7.5999, train_accuracy: 0.1562, time: 1.02 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 009600, loss: 9.7537, train_accuracy: 0.1406, time: 1.08 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 009700, loss: 10.3980, train_accuracy: 0.1406, time: 1.13 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 009800, loss: 6.9880, train_accuracy: 0.2031, time: 1.02 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 009900, loss: 7.8207, train_accuracy: 0.1875, time: 1.03 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 010000, loss: 7.7494, train_accuracy: 0.2188, time: 0.93 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 010100, loss: 8.4192, train_accuracy: 0.1719, time: 0.97 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 010200, loss: 8.5442, train_accuracy: 0.1719, time: 1.07 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 010300, loss: 8.1309, train_accuracy: 0.2031, time: 1.14 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 010400, loss: 8.3740, train_accuracy: 0.2344, time: 1.17 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 010500, loss: 9.7054, train_accuracy: 0.1719, time: 1.18 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 010600, loss: 6.6225, train_accuracy: 0.2344, time: 0.98 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 010700, loss: 7.8592, train_accuracy: 0.1250, time: 0.91 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 010800, loss: 7.1321, train_accuracy: 0.2500, time: 0.94 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 010900, loss: 7.4140, train_accuracy: 0.2188, time: 0.93 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 011000, loss: 6.6804, train_accuracy: 0.2656, time: 1.03 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 011100, loss: 8.0686, train_accuracy: 0.1562, time: 1.12 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 011200, loss: 7.7478, train_accuracy: 0.2500, time: 1.01 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 011300, loss: 8.6322, train_accuracy: 0.1406, time: 0.96 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 011400, loss: 8.8110, train_accuracy: 0.2500, time: 0.91 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 011500, loss: 7.6465, train_accuracy: 0.1719, time: 0.97 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 011600, loss: 8.4004, train_accuracy: 0.1875, time: 0.99 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 011700, loss: 9.1915, train_accuracy: 0.2344, time: 0.97 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 011800, loss: 8.7890, train_accuracy: 0.1094, time: 1.01 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 011900, loss: 9.3216, train_accuracy: 0.2031, time: 1.19 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 012000, loss: 8.4624, train_accuracy: 0.2188, time: 1.32 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 012100, loss: 8.5092, train_accuracy: 0.2344, time: 1.33 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 012200, loss: 7.8291, train_accuracy: 0.1875, time: 1.35 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 012300, loss: 7.9684, train_accuracy: 0.1094, time: 1.36 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 012400, loss: 8.9666, train_accuracy: 0.2500, time: 1.22 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 012500, loss: 7.5899, train_accuracy: 0.1719, time: 1.18 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 012600, loss: 7.4031, train_accuracy: 0.2812, time: 1.26 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 012700, loss: 7.8611, train_accuracy: 0.1562, time: 1.45 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 012800, loss: 7.4139, train_accuracy: 0.2188, time: 1.30 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 012900, loss: 7.3891, train_accuracy: 0.1719, time: 1.11 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 013000, loss: 6.8772, train_accuracy: 0.2031, time: 1.05 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 013100, loss: 6.0491, train_accuracy: 0.3281, time: 1.08 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 013200, loss: 7.4523, train_accuracy: 0.1719, time: 1.10 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 013300, loss: 9.1223, train_accuracy: 0.1562, time: 1.07 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 013400, loss: 6.1837, train_accuracy: 0.2656, time: 1.29 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 013500, loss: 8.8041, train_accuracy: 0.2031, time: 1.41 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 013600, loss: 8.2979, train_accuracy: 0.1875, time: 1.36 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 013700, loss: 6.5253, train_accuracy: 0.2500, time: 1.39 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 013800, loss: 7.9301, train_accuracy: 0.1875, time: 1.38 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 013900, loss: 7.6708, train_accuracy: 0.1406, time: 1.11 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 014000, loss: 7.5678, train_accuracy: 0.2500, time: 1.16 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 014100, loss: 5.8814, train_accuracy: 0.3906, time: 1.27 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 014200, loss: 8.5581, train_accuracy: 0.2344, time: 1.34 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 014300, loss: 6.9447, train_accuracy: 0.1875, time: 1.35 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 014400, loss: 7.4482, train_accuracy: 0.2188, time: 1.36 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 014500, loss: 7.6697, train_accuracy: 0.2344, time: 1.13 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 014600, loss: 8.5786, train_accuracy: 0.1719, time: 1.05 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 014700, loss: 8.8884, train_accuracy: 0.2188, time: 1.06 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 014800, loss: 6.5344, train_accuracy: 0.2188, time: 1.24 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 014900, loss: 7.8995, train_accuracy: 0.1719, time: 1.32 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 015000, loss: 6.2219, train_accuracy: 0.3438, time: 1.36 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 015100, loss: 6.9616, train_accuracy: 0.2031, time: 1.42 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 015200, loss: 7.3569, train_accuracy: 0.2344, time: 1.35 s/iter, learning rate: 0.01\n",
      "Epoch 1/11, Iters: 015300, loss: 7.0718, train_accuracy: 0.2188, time: 1.15 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 015400, loss: 8.0494, train_accuracy: 0.1250, time: 0.75 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 015500, loss: 7.7442, train_accuracy: 0.2188, time: 1.08 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 015600, loss: 7.1455, train_accuracy: 0.2188, time: 1.25 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 015700, loss: 6.9444, train_accuracy: 0.3281, time: 1.29 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 015800, loss: 6.6088, train_accuracy: 0.2656, time: 1.27 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 015900, loss: 7.8341, train_accuracy: 0.2656, time: 1.24 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 016000, loss: 7.6368, train_accuracy: 0.2812, time: 1.10 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 016100, loss: 8.0387, train_accuracy: 0.1719, time: 1.04 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 016200, loss: 8.0617, train_accuracy: 0.1875, time: 1.04 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 016300, loss: 9.0584, train_accuracy: 0.1562, time: 0.91 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 016400, loss: 7.1548, train_accuracy: 0.3281, time: 1.03 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 016500, loss: 6.3057, train_accuracy: 0.2500, time: 0.92 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 016600, loss: 6.7714, train_accuracy: 0.2188, time: 0.96 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 016700, loss: 6.5249, train_accuracy: 0.3125, time: 1.08 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 016800, loss: 8.2030, train_accuracy: 0.2031, time: 1.06 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 016900, loss: 9.6393, train_accuracy: 0.1875, time: 1.17 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 017000, loss: 6.5042, train_accuracy: 0.3281, time: 1.17 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 017100, loss: 7.5865, train_accuracy: 0.2344, time: 1.17 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 017200, loss: 7.6133, train_accuracy: 0.2500, time: 1.11 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 017300, loss: 7.7090, train_accuracy: 0.2656, time: 0.97 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 017400, loss: 5.5253, train_accuracy: 0.2969, time: 0.97 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 017500, loss: 8.4446, train_accuracy: 0.1719, time: 0.90 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 017600, loss: 6.4375, train_accuracy: 0.2500, time: 0.97 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 017700, loss: 7.2059, train_accuracy: 0.1719, time: 0.97 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 017800, loss: 7.8293, train_accuracy: 0.2500, time: 0.93 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 017900, loss: 7.9315, train_accuracy: 0.1719, time: 1.07 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 018000, loss: 8.5199, train_accuracy: 0.2188, time: 1.23 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 018100, loss: 7.9900, train_accuracy: 0.1719, time: 1.22 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 018200, loss: 7.1702, train_accuracy: 0.2812, time: 1.27 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 018300, loss: 6.3105, train_accuracy: 0.3594, time: 1.21 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 018400, loss: 7.2885, train_accuracy: 0.2812, time: 1.20 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 018500, loss: 6.5486, train_accuracy: 0.2188, time: 1.04 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 018600, loss: 7.4608, train_accuracy: 0.2188, time: 1.08 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 018700, loss: 7.0396, train_accuracy: 0.1875, time: 1.03 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 018800, loss: 7.6407, train_accuracy: 0.2031, time: 1.12 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 018900, loss: 6.1361, train_accuracy: 0.2500, time: 1.21 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 019000, loss: 6.7429, train_accuracy: 0.3594, time: 1.22 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 019100, loss: 7.4983, train_accuracy: 0.2344, time: 1.24 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 019200, loss: 8.5522, train_accuracy: 0.2031, time: 1.30 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 019300, loss: 5.6082, train_accuracy: 0.2500, time: 1.26 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 019400, loss: 7.5988, train_accuracy: 0.1719, time: 1.22 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 019500, loss: 7.3979, train_accuracy: 0.1562, time: 1.28 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 019600, loss: 9.0735, train_accuracy: 0.2031, time: 1.26 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 019700, loss: 8.1363, train_accuracy: 0.2188, time: 1.10 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 019800, loss: 7.0891, train_accuracy: 0.2188, time: 1.05 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 019900, loss: 6.4654, train_accuracy: 0.2656, time: 1.16 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 020000, loss: 6.7345, train_accuracy: 0.2344, time: 1.12 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 020100, loss: 6.8412, train_accuracy: 0.2969, time: 1.21 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 020200, loss: 6.4268, train_accuracy: 0.2500, time: 1.10 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 020300, loss: 8.1280, train_accuracy: 0.2500, time: 1.22 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 020400, loss: 6.4334, train_accuracy: 0.2969, time: 1.40 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 020500, loss: 7.1539, train_accuracy: 0.2344, time: 1.37 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 020600, loss: 7.3665, train_accuracy: 0.2031, time: 1.38 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 020700, loss: 7.7512, train_accuracy: 0.1875, time: 1.48 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 020800, loss: 8.0103, train_accuracy: 0.2344, time: 1.17 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 020900, loss: 6.6724, train_accuracy: 0.1875, time: 1.18 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 021000, loss: 9.0387, train_accuracy: 0.2031, time: 1.31 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 021100, loss: 7.2693, train_accuracy: 0.2344, time: 1.39 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 021200, loss: 8.2588, train_accuracy: 0.1406, time: 1.44 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 021300, loss: 6.0666, train_accuracy: 0.3125, time: 1.44 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 021400, loss: 8.1026, train_accuracy: 0.1406, time: 1.37 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 021500, loss: 8.0624, train_accuracy: 0.1562, time: 1.42 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 021600, loss: 5.9734, train_accuracy: 0.2344, time: 1.41 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 021700, loss: 6.5778, train_accuracy: 0.3281, time: 1.24 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 021800, loss: 6.3499, train_accuracy: 0.2812, time: 1.25 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 021900, loss: 6.6834, train_accuracy: 0.2344, time: 1.18 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 022000, loss: 8.6732, train_accuracy: 0.1875, time: 1.16 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 022100, loss: 5.8420, train_accuracy: 0.2969, time: 1.19 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 022200, loss: 7.0140, train_accuracy: 0.2500, time: 1.18 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 022300, loss: 8.8699, train_accuracy: 0.1719, time: 1.17 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 022400, loss: 6.7601, train_accuracy: 0.3125, time: 1.31 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 022500, loss: 7.3592, train_accuracy: 0.2500, time: 1.42 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 022600, loss: 7.1484, train_accuracy: 0.2344, time: 1.37 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 022700, loss: 8.0008, train_accuracy: 0.2031, time: 1.39 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 022800, loss: 7.1494, train_accuracy: 0.2812, time: 1.37 s/iter, learning rate: 0.01\n",
      "Epoch 2/11, Iters: 022900, loss: 8.3667, train_accuracy: 0.2188, time: 1.24 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 023000, loss: 5.5171, train_accuracy: 0.2812, time: 0.02 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 023100, loss: 6.3523, train_accuracy: 0.2969, time: 1.04 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 023200, loss: 6.1587, train_accuracy: 0.3125, time: 1.04 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 023300, loss: 7.3444, train_accuracy: 0.2344, time: 1.15 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 023400, loss: 7.7745, train_accuracy: 0.2656, time: 1.12 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 023500, loss: 5.9769, train_accuracy: 0.2969, time: 1.10 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 023600, loss: 7.3886, train_accuracy: 0.3750, time: 1.18 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 023700, loss: 8.2851, train_accuracy: 0.1719, time: 1.05 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 023800, loss: 6.2307, train_accuracy: 0.2188, time: 1.15 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 023900, loss: 8.2670, train_accuracy: 0.2188, time: 1.09 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 024000, loss: 6.8807, train_accuracy: 0.2656, time: 0.99 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 024100, loss: 6.5045, train_accuracy: 0.2969, time: 0.93 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 024200, loss: 7.3474, train_accuracy: 0.2812, time: 0.91 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 024300, loss: 6.1602, train_accuracy: 0.3125, time: 0.81 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 024400, loss: 6.5140, train_accuracy: 0.2500, time: 0.89 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 024500, loss: 6.2265, train_accuracy: 0.2656, time: 0.80 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 024600, loss: 7.3901, train_accuracy: 0.2812, time: 0.85 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 024700, loss: 8.0758, train_accuracy: 0.2500, time: 0.88 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 024800, loss: 6.4097, train_accuracy: 0.2344, time: 0.85 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 024900, loss: 7.6499, train_accuracy: 0.2656, time: 0.92 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 025000, loss: 7.0906, train_accuracy: 0.2656, time: 0.88 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 025100, loss: 7.4060, train_accuracy: 0.2344, time: 0.82 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 025200, loss: 8.6484, train_accuracy: 0.2188, time: 0.87 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 025300, loss: 7.2752, train_accuracy: 0.2031, time: 0.87 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 025400, loss: 7.4697, train_accuracy: 0.2031, time: 0.85 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 025500, loss: 7.9517, train_accuracy: 0.1719, time: 0.84 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 025600, loss: 7.4461, train_accuracy: 0.2031, time: 0.88 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 025700, loss: 7.2475, train_accuracy: 0.2656, time: 0.91 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 025800, loss: 7.5360, train_accuracy: 0.2188, time: 0.92 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 025900, loss: 9.5598, train_accuracy: 0.2344, time: 1.05 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 026000, loss: 7.0885, train_accuracy: 0.1719, time: 1.01 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 026100, loss: 6.3615, train_accuracy: 0.2656, time: 1.14 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 026200, loss: 8.1465, train_accuracy: 0.1719, time: 1.08 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 026300, loss: 8.5284, train_accuracy: 0.2031, time: 1.13 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 026400, loss: 6.8784, train_accuracy: 0.2500, time: 1.20 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 026500, loss: 6.3668, train_accuracy: 0.2812, time: 0.95 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 026600, loss: 7.8891, train_accuracy: 0.2500, time: 0.99 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 026700, loss: 6.1685, train_accuracy: 0.2969, time: 0.95 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 026800, loss: 7.1054, train_accuracy: 0.1875, time: 1.19 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 026900, loss: 6.7551, train_accuracy: 0.3125, time: 1.17 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 027000, loss: 8.1639, train_accuracy: 0.2031, time: 1.15 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 027100, loss: 5.8031, train_accuracy: 0.2812, time: 1.21 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 027200, loss: 7.4213, train_accuracy: 0.1719, time: 1.28 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 027300, loss: 8.0230, train_accuracy: 0.2344, time: 1.10 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 027400, loss: 10.1932, train_accuracy: 0.2031, time: 1.05 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 027500, loss: 8.1104, train_accuracy: 0.2188, time: 1.13 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 027600, loss: 5.4855, train_accuracy: 0.2500, time: 1.31 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 027700, loss: 7.3460, train_accuracy: 0.2969, time: 1.28 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 027800, loss: 6.9824, train_accuracy: 0.2500, time: 1.33 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 027900, loss: 7.5352, train_accuracy: 0.2500, time: 1.31 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 028000, loss: 7.5547, train_accuracy: 0.2812, time: 1.23 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 028100, loss: 5.5703, train_accuracy: 0.3125, time: 1.12 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 028200, loss: 6.1393, train_accuracy: 0.2656, time: 1.38 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 028300, loss: 7.0076, train_accuracy: 0.2812, time: 1.22 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 028400, loss: 8.5389, train_accuracy: 0.2031, time: 1.08 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 028500, loss: 6.5242, train_accuracy: 0.2812, time: 1.07 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 028600, loss: 7.3613, train_accuracy: 0.2656, time: 1.06 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 028700, loss: 5.4743, train_accuracy: 0.3750, time: 1.07 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 028800, loss: 5.6486, train_accuracy: 0.3125, time: 1.09 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 028900, loss: 7.0896, train_accuracy: 0.1875, time: 1.09 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 029000, loss: 8.2780, train_accuracy: 0.1875, time: 1.11 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 029100, loss: 6.8114, train_accuracy: 0.2188, time: 1.21 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 029200, loss: 6.5949, train_accuracy: 0.2031, time: 1.39 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 029300, loss: 8.0921, train_accuracy: 0.2031, time: 1.41 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 029400, loss: 8.6124, train_accuracy: 0.2188, time: 1.40 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 029500, loss: 9.1266, train_accuracy: 0.0781, time: 1.26 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 029600, loss: 6.6038, train_accuracy: 0.3281, time: 1.12 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 029700, loss: 6.0129, train_accuracy: 0.2500, time: 1.11 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 029800, loss: 8.1200, train_accuracy: 0.2500, time: 1.29 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 029900, loss: 6.5297, train_accuracy: 0.2812, time: 1.34 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 030000, loss: 7.0377, train_accuracy: 0.2656, time: 1.37 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 030100, loss: 6.7266, train_accuracy: 0.2500, time: 1.39 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 030200, loss: 6.3632, train_accuracy: 0.3438, time: 1.29 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 030300, loss: 8.1582, train_accuracy: 0.1719, time: 1.17 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 030400, loss: 6.3281, train_accuracy: 0.3125, time: 1.17 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 030500, loss: 6.7810, train_accuracy: 0.2812, time: 1.41 s/iter, learning rate: 0.01\n",
      "Epoch 3/11, Iters: 030600, loss: 7.9741, train_accuracy: 0.2188, time: 1.38 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 030700, loss: 6.2576, train_accuracy: 0.3281, time: 0.40 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 030800, loss: 5.7270, train_accuracy: 0.2969, time: 1.29 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 030900, loss: 6.6106, train_accuracy: 0.2656, time: 1.14 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 031000, loss: 8.1420, train_accuracy: 0.2031, time: 1.02 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 031100, loss: 7.2940, train_accuracy: 0.1562, time: 1.07 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 031200, loss: 5.9824, train_accuracy: 0.3125, time: 1.14 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 031300, loss: 6.5635, train_accuracy: 0.3438, time: 1.28 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 031400, loss: 7.4201, train_accuracy: 0.2656, time: 1.23 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 031500, loss: 8.8667, train_accuracy: 0.2344, time: 1.25 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 031600, loss: 6.8882, train_accuracy: 0.2969, time: 1.25 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 031700, loss: 7.7803, train_accuracy: 0.2344, time: 1.15 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 031800, loss: 7.5579, train_accuracy: 0.2656, time: 1.03 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 031900, loss: 6.8057, train_accuracy: 0.2344, time: 1.10 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 032000, loss: 7.4567, train_accuracy: 0.2031, time: 1.28 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 032100, loss: 6.9394, train_accuracy: 0.2656, time: 1.29 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 032200, loss: 7.8485, train_accuracy: 0.2344, time: 1.24 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 032300, loss: 7.3996, train_accuracy: 0.2031, time: 1.26 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 032400, loss: 6.9005, train_accuracy: 0.2031, time: 1.23 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 032500, loss: 4.2428, train_accuracy: 0.3125, time: 1.06 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 032600, loss: 5.6372, train_accuracy: 0.3438, time: 1.08 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 032700, loss: 9.3540, train_accuracy: 0.2031, time: 1.15 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 032800, loss: 8.1419, train_accuracy: 0.2344, time: 1.20 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 032900, loss: 6.5167, train_accuracy: 0.2500, time: 1.27 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 033000, loss: 7.9836, train_accuracy: 0.2656, time: 1.22 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 033100, loss: 6.4190, train_accuracy: 0.3125, time: 1.27 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 033200, loss: 6.0782, train_accuracy: 0.2812, time: 1.17 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 033300, loss: 5.9737, train_accuracy: 0.3438, time: 1.04 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 033400, loss: 6.3126, train_accuracy: 0.2500, time: 1.06 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 033500, loss: 6.9615, train_accuracy: 0.2656, time: 1.23 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 033600, loss: 6.9386, train_accuracy: 0.2500, time: 1.29 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 033700, loss: 9.0327, train_accuracy: 0.1562, time: 1.27 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 033800, loss: 6.4174, train_accuracy: 0.2031, time: 1.28 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 033900, loss: 8.2648, train_accuracy: 0.1250, time: 1.25 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 034000, loss: 7.0057, train_accuracy: 0.1094, time: 1.04 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 034100, loss: 6.9488, train_accuracy: 0.1875, time: 1.10 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 034200, loss: 6.9432, train_accuracy: 0.2344, time: 1.08 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 034300, loss: 7.7710, train_accuracy: 0.2656, time: 1.24 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 034400, loss: 7.5697, train_accuracy: 0.1875, time: 1.26 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 034500, loss: 7.3959, train_accuracy: 0.2344, time: 1.27 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 034600, loss: 7.7517, train_accuracy: 0.1719, time: 1.26 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 034700, loss: 8.0745, train_accuracy: 0.2188, time: 1.16 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 034800, loss: 7.6034, train_accuracy: 0.3281, time: 1.11 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 034900, loss: 6.8572, train_accuracy: 0.2812, time: 1.10 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 035000, loss: 8.7683, train_accuracy: 0.2188, time: 1.19 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 035100, loss: 7.7098, train_accuracy: 0.3125, time: 1.25 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 035200, loss: 6.3076, train_accuracy: 0.2969, time: 1.27 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 035300, loss: 6.3593, train_accuracy: 0.2500, time: 1.32 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 035400, loss: 8.0035, train_accuracy: 0.2188, time: 1.33 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 035500, loss: 6.5656, train_accuracy: 0.2656, time: 1.20 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 035600, loss: 7.8671, train_accuracy: 0.2656, time: 1.10 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 035700, loss: 7.9041, train_accuracy: 0.3125, time: 1.19 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 035800, loss: 7.0514, train_accuracy: 0.2969, time: 1.34 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 035900, loss: 6.4072, train_accuracy: 0.3438, time: 1.29 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 036000, loss: 7.4780, train_accuracy: 0.2031, time: 1.33 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 036100, loss: 7.3085, train_accuracy: 0.2969, time: 1.36 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 036200, loss: 7.6723, train_accuracy: 0.2656, time: 1.19 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 036300, loss: 6.8043, train_accuracy: 0.2812, time: 1.15 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 036400, loss: 7.0857, train_accuracy: 0.1719, time: 1.25 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 036500, loss: 7.9235, train_accuracy: 0.1562, time: 1.32 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 036600, loss: 7.5683, train_accuracy: 0.2656, time: 1.42 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 036700, loss: 5.3002, train_accuracy: 0.3281, time: 1.38 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 036800, loss: 6.5400, train_accuracy: 0.2812, time: 1.33 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 036900, loss: 6.4043, train_accuracy: 0.1875, time: 1.15 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 037000, loss: 7.5898, train_accuracy: 0.2656, time: 1.16 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 037100, loss: 7.6967, train_accuracy: 0.1719, time: 1.23 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 037200, loss: 7.9833, train_accuracy: 0.2344, time: 1.39 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 037300, loss: 6.5862, train_accuracy: 0.2500, time: 1.40 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 037400, loss: 6.4161, train_accuracy: 0.2656, time: 1.47 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 037500, loss: 5.9466, train_accuracy: 0.2500, time: 1.39 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 037600, loss: 5.9472, train_accuracy: 0.3438, time: 1.21 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 037700, loss: 7.9427, train_accuracy: 0.2969, time: 1.38 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 037800, loss: 6.3656, train_accuracy: 0.3125, time: 1.42 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 037900, loss: 7.2511, train_accuracy: 0.2031, time: 1.40 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 038000, loss: 7.1305, train_accuracy: 0.2344, time: 1.38 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 038100, loss: 7.0822, train_accuracy: 0.2188, time: 1.35 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 038200, loss: 8.5026, train_accuracy: 0.2344, time: 1.23 s/iter, learning rate: 0.01\n",
      "Epoch 4/11, Iters: 038300, loss: 6.9896, train_accuracy: 0.2344, time: 1.19 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 038400, loss: 5.3155, train_accuracy: 0.3594, time: 0.62 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 038500, loss: 7.8302, train_accuracy: 0.2656, time: 0.84 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 038600, loss: 6.5094, train_accuracy: 0.2812, time: 0.89 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 038700, loss: 6.8687, train_accuracy: 0.2812, time: 1.05 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 038800, loss: 5.9842, train_accuracy: 0.2656, time: 0.98 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 038900, loss: 8.1498, train_accuracy: 0.2656, time: 1.05 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 039000, loss: 7.3550, train_accuracy: 0.2031, time: 1.08 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 039100, loss: 5.0925, train_accuracy: 0.2812, time: 1.10 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 039200, loss: 6.7898, train_accuracy: 0.2656, time: 1.07 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 039300, loss: 8.6663, train_accuracy: 0.2500, time: 0.94 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 039400, loss: 6.5233, train_accuracy: 0.2656, time: 1.09 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 039500, loss: 7.0697, train_accuracy: 0.2812, time: 1.06 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 039600, loss: 5.9723, train_accuracy: 0.2656, time: 1.10 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 039700, loss: 5.9224, train_accuracy: 0.2500, time: 1.08 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 039800, loss: 7.3055, train_accuracy: 0.2344, time: 1.15 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 039900, loss: 6.6653, train_accuracy: 0.2344, time: 1.06 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 040000, loss: 5.7704, train_accuracy: 0.2969, time: 0.93 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 040100, loss: 7.0410, train_accuracy: 0.1250, time: 0.99 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 040200, loss: 6.8976, train_accuracy: 0.2969, time: 0.93 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 040300, loss: 7.4131, train_accuracy: 0.1875, time: 1.09 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 040400, loss: 5.8807, train_accuracy: 0.3125, time: 1.05 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 040500, loss: 6.6519, train_accuracy: 0.2344, time: 1.04 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 040600, loss: 7.6657, train_accuracy: 0.2500, time: 1.11 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 040700, loss: 6.3613, train_accuracy: 0.2969, time: 1.07 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 040800, loss: 7.4370, train_accuracy: 0.2188, time: 1.09 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 040900, loss: 7.3788, train_accuracy: 0.1875, time: 1.06 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 041000, loss: 7.4188, train_accuracy: 0.2031, time: 0.89 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 041100, loss: 7.3102, train_accuracy: 0.2031, time: 1.07 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 041200, loss: 7.1880, train_accuracy: 0.2656, time: 1.11 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 041300, loss: 6.5585, train_accuracy: 0.2500, time: 1.06 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 041400, loss: 9.0834, train_accuracy: 0.2031, time: 1.11 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 041500, loss: 8.2786, train_accuracy: 0.2031, time: 1.06 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 041600, loss: 6.6282, train_accuracy: 0.2812, time: 1.01 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 041700, loss: 6.5542, train_accuracy: 0.2812, time: 1.08 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 041800, loss: 6.5280, train_accuracy: 0.1875, time: 1.09 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 041900, loss: 8.0243, train_accuracy: 0.2969, time: 1.12 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 042000, loss: 7.7868, train_accuracy: 0.2812, time: 1.29 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 042100, loss: 6.2136, train_accuracy: 0.2188, time: 1.31 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 042200, loss: 7.8071, train_accuracy: 0.2656, time: 1.33 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 042300, loss: 6.9683, train_accuracy: 0.1406, time: 1.30 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 042400, loss: 7.7621, train_accuracy: 0.1875, time: 1.33 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 042500, loss: 7.5483, train_accuracy: 0.1875, time: 1.21 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 042600, loss: 6.7259, train_accuracy: 0.3438, time: 1.17 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 042700, loss: 5.9914, train_accuracy: 0.3125, time: 1.29 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 042800, loss: 6.8638, train_accuracy: 0.2969, time: 1.33 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 042900, loss: 7.1069, train_accuracy: 0.2500, time: 1.36 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 043000, loss: 6.6410, train_accuracy: 0.2656, time: 1.35 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 043100, loss: 7.6842, train_accuracy: 0.2969, time: 1.22 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 043200, loss: 6.6244, train_accuracy: 0.3281, time: 1.12 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 043300, loss: 7.7390, train_accuracy: 0.2344, time: 1.13 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 043400, loss: 7.5479, train_accuracy: 0.2188, time: 1.32 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 043500, loss: 7.3053, train_accuracy: 0.2812, time: 1.36 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 043600, loss: 7.5694, train_accuracy: 0.2656, time: 1.34 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 043700, loss: 7.0262, train_accuracy: 0.2031, time: 1.30 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 043800, loss: 7.4430, train_accuracy: 0.2344, time: 1.27 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 043900, loss: 6.4729, train_accuracy: 0.3281, time: 1.19 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 044000, loss: 7.0311, train_accuracy: 0.2031, time: 1.14 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 044100, loss: 7.1246, train_accuracy: 0.2031, time: 1.30 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 044200, loss: 7.3793, train_accuracy: 0.2656, time: 1.31 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 044300, loss: 7.2003, train_accuracy: 0.2656, time: 1.34 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 044400, loss: 6.2328, train_accuracy: 0.3438, time: 1.37 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 044500, loss: 6.6171, train_accuracy: 0.2344, time: 1.32 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 044600, loss: 6.1098, train_accuracy: 0.3594, time: 1.14 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 044700, loss: 8.7155, train_accuracy: 0.2344, time: 1.19 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 044800, loss: 6.4054, train_accuracy: 0.3125, time: 1.32 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 044900, loss: 6.3568, train_accuracy: 0.2188, time: 1.36 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 045000, loss: 7.2953, train_accuracy: 0.2500, time: 1.39 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 045100, loss: 7.4249, train_accuracy: 0.2031, time: 1.38 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 045200, loss: 7.3614, train_accuracy: 0.2500, time: 1.34 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 045300, loss: 7.7794, train_accuracy: 0.2188, time: 1.06 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 045400, loss: 7.3432, train_accuracy: 0.2656, time: 1.05 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 045500, loss: 6.9221, train_accuracy: 0.3438, time: 1.17 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 045600, loss: 6.6114, train_accuracy: 0.3125, time: 1.26 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 045700, loss: 7.5993, train_accuracy: 0.2656, time: 1.21 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 045800, loss: 4.8668, train_accuracy: 0.4062, time: 1.28 s/iter, learning rate: 0.01\n",
      "Epoch 5/11, Iters: 045900, loss: 7.9292, train_accuracy: 0.1719, time: 1.33 s/iter, learning rate: 0.01\n",
      "Epoch 6/11, Iters: 046000, loss: 7.0453, train_accuracy: 0.2344, time: 0.03 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 046100, loss: 6.3306, train_accuracy: 0.3750, time: 0.78 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 046200, loss: 5.9234, train_accuracy: 0.3438, time: 0.77 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 046300, loss: 7.0097, train_accuracy: 0.3906, time: 0.84 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 046400, loss: 6.3874, train_accuracy: 0.3125, time: 0.89 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 046500, loss: 7.3055, train_accuracy: 0.2031, time: 0.86 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 046600, loss: 5.9199, train_accuracy: 0.2500, time: 0.98 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 046700, loss: 5.8558, train_accuracy: 0.3281, time: 0.90 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 046800, loss: 6.8697, train_accuracy: 0.2969, time: 0.91 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 046900, loss: 5.5618, train_accuracy: 0.3906, time: 0.95 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 047000, loss: 7.4241, train_accuracy: 0.2656, time: 0.83 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 047100, loss: 6.0306, train_accuracy: 0.4844, time: 0.78 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 047200, loss: 5.7232, train_accuracy: 0.4219, time: 0.80 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 047300, loss: 6.9910, train_accuracy: 0.2969, time: 0.82 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 047400, loss: 6.1150, train_accuracy: 0.3438, time: 0.90 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 047500, loss: 7.5690, train_accuracy: 0.2656, time: 0.97 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 047600, loss: 6.0947, train_accuracy: 0.3281, time: 0.92 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 047700, loss: 5.8808, train_accuracy: 0.2969, time: 0.99 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 047800, loss: 6.2325, train_accuracy: 0.2812, time: 0.92 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 047900, loss: 5.3434, train_accuracy: 0.4375, time: 1.05 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 048000, loss: 5.8909, train_accuracy: 0.3594, time: 0.98 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 048100, loss: 6.6909, train_accuracy: 0.3438, time: 0.90 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 048200, loss: 4.7762, train_accuracy: 0.3594, time: 1.02 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 048300, loss: 6.0488, train_accuracy: 0.4375, time: 1.01 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 048400, loss: 6.8645, train_accuracy: 0.3750, time: 1.00 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 048500, loss: 5.5928, train_accuracy: 0.3281, time: 1.02 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 048600, loss: 5.9913, train_accuracy: 0.3594, time: 1.03 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 048700, loss: 6.8248, train_accuracy: 0.2344, time: 1.04 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 048800, loss: 5.4082, train_accuracy: 0.2969, time: 0.90 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 048900, loss: 5.9728, train_accuracy: 0.3438, time: 0.91 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 049000, loss: 7.1602, train_accuracy: 0.3438, time: 0.94 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 049100, loss: 6.0503, train_accuracy: 0.2969, time: 0.88 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 049200, loss: 6.0194, train_accuracy: 0.3750, time: 1.10 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 049300, loss: 5.8433, train_accuracy: 0.3438, time: 1.07 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 049400, loss: 5.3826, train_accuracy: 0.4688, time: 1.15 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 049500, loss: 5.7548, train_accuracy: 0.4219, time: 1.10 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 049600, loss: 6.3573, train_accuracy: 0.3594, time: 1.14 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 049700, loss: 6.9536, train_accuracy: 0.2344, time: 1.09 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 049800, loss: 7.2118, train_accuracy: 0.4062, time: 1.23 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 049900, loss: 6.9548, train_accuracy: 0.2969, time: 1.21 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 050000, loss: 7.2463, train_accuracy: 0.3281, time: 1.21 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 050100, loss: 6.7413, train_accuracy: 0.3594, time: 1.17 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 050200, loss: 5.4326, train_accuracy: 0.3750, time: 1.18 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 050300, loss: 6.4580, train_accuracy: 0.3125, time: 1.01 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 050400, loss: 5.6930, train_accuracy: 0.3438, time: 1.15 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 050500, loss: 8.4052, train_accuracy: 0.2031, time: 1.06 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 050600, loss: 6.7307, train_accuracy: 0.2188, time: 1.05 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 050700, loss: 6.4432, train_accuracy: 0.3750, time: 1.18 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 050800, loss: 7.5408, train_accuracy: 0.2344, time: 1.28 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 050900, loss: 6.5301, train_accuracy: 0.3438, time: 1.33 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 051000, loss: 7.8746, train_accuracy: 0.2500, time: 1.30 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 051100, loss: 5.2623, train_accuracy: 0.4375, time: 1.38 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 051200, loss: 7.2432, train_accuracy: 0.3125, time: 1.38 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 051300, loss: 4.6120, train_accuracy: 0.3281, time: 1.24 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 051400, loss: 5.9300, train_accuracy: 0.3906, time: 1.13 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 051500, loss: 5.8872, train_accuracy: 0.2969, time: 1.33 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 051600, loss: 6.4135, train_accuracy: 0.2969, time: 1.36 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 051700, loss: 5.0700, train_accuracy: 0.3750, time: 1.31 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 051800, loss: 6.4650, train_accuracy: 0.3281, time: 1.39 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 051900, loss: 5.7785, train_accuracy: 0.3906, time: 1.25 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 052000, loss: 7.2953, train_accuracy: 0.2656, time: 1.23 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 052100, loss: 6.0146, train_accuracy: 0.3906, time: 1.23 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 052200, loss: 6.4788, train_accuracy: 0.2344, time: 1.42 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 052300, loss: 5.9492, train_accuracy: 0.3750, time: 1.36 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 052400, loss: 6.8367, train_accuracy: 0.3281, time: 1.39 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 052500, loss: 6.8445, train_accuracy: 0.2812, time: 1.33 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 052600, loss: 6.3172, train_accuracy: 0.3125, time: 1.21 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 052700, loss: 6.3536, train_accuracy: 0.4062, time: 1.19 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 052800, loss: 7.4331, train_accuracy: 0.2656, time: 1.15 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 052900, loss: 6.3358, train_accuracy: 0.3281, time: 1.39 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 053000, loss: 7.5778, train_accuracy: 0.2656, time: 1.37 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 053100, loss: 7.3236, train_accuracy: 0.2188, time: 1.41 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 053200, loss: 6.1130, train_accuracy: 0.2812, time: 1.35 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 053300, loss: 5.1545, train_accuracy: 0.4219, time: 1.27 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 053400, loss: 6.9427, train_accuracy: 0.3750, time: 1.16 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 053500, loss: 6.9801, train_accuracy: 0.3438, time: 1.22 s/iter, learning rate: 0.003\n",
      "Epoch 6/11, Iters: 053600, loss: 6.8566, train_accuracy: 0.3438, time: 1.38 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 053700, loss: 5.8409, train_accuracy: 0.4062, time: 0.38 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 053800, loss: 6.5460, train_accuracy: 0.3281, time: 1.14 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 053900, loss: 5.9616, train_accuracy: 0.2500, time: 1.19 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 054000, loss: 5.1554, train_accuracy: 0.3125, time: 1.06 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 054100, loss: 8.0835, train_accuracy: 0.2188, time: 1.03 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 054200, loss: 5.5540, train_accuracy: 0.4219, time: 0.95 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 054300, loss: 5.6248, train_accuracy: 0.2969, time: 1.01 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 054400, loss: 4.8415, train_accuracy: 0.4531, time: 0.94 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 054500, loss: 5.9981, train_accuracy: 0.2812, time: 0.90 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 054600, loss: 5.4992, train_accuracy: 0.3125, time: 0.88 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 054700, loss: 4.4581, train_accuracy: 0.4688, time: 0.90 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 054800, loss: 5.4702, train_accuracy: 0.3438, time: 0.92 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 054900, loss: 5.5878, train_accuracy: 0.3594, time: 0.87 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 055000, loss: 6.3906, train_accuracy: 0.3281, time: 0.86 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 055100, loss: 5.3494, train_accuracy: 0.4062, time: 0.95 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 055200, loss: 5.6562, train_accuracy: 0.3594, time: 0.96 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 055300, loss: 5.6751, train_accuracy: 0.3438, time: 1.06 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 055400, loss: 6.1873, train_accuracy: 0.3438, time: 1.10 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 055500, loss: 5.8957, train_accuracy: 0.3438, time: 1.12 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 055600, loss: 7.2913, train_accuracy: 0.3594, time: 1.14 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 055700, loss: 7.4794, train_accuracy: 0.3281, time: 1.14 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 055800, loss: 4.8193, train_accuracy: 0.3750, time: 1.07 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 055900, loss: 6.8760, train_accuracy: 0.3125, time: 1.04 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 056000, loss: 6.5774, train_accuracy: 0.2812, time: 0.93 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 056100, loss: 6.4337, train_accuracy: 0.3438, time: 1.03 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 056200, loss: 5.0912, train_accuracy: 0.4375, time: 1.10 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 056300, loss: 6.3787, train_accuracy: 0.3438, time: 1.14 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 056400, loss: 6.0564, train_accuracy: 0.4062, time: 1.18 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 056500, loss: 4.8754, train_accuracy: 0.3906, time: 1.12 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 056600, loss: 6.9727, train_accuracy: 0.3125, time: 1.09 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 056700, loss: 6.5306, train_accuracy: 0.2656, time: 1.08 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 056800, loss: 6.8525, train_accuracy: 0.2969, time: 0.96 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 056900, loss: 4.9587, train_accuracy: 0.3750, time: 1.04 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 057000, loss: 6.5384, train_accuracy: 0.2500, time: 1.03 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 057100, loss: 7.0559, train_accuracy: 0.3125, time: 1.16 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 057200, loss: 6.0574, train_accuracy: 0.3438, time: 1.18 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 057300, loss: 5.5447, train_accuracy: 0.3750, time: 1.08 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 057400, loss: 6.4992, train_accuracy: 0.3281, time: 1.24 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 057500, loss: 6.9990, train_accuracy: 0.3125, time: 1.15 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 057600, loss: 5.4478, train_accuracy: 0.2969, time: 1.02 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 057700, loss: 6.3564, train_accuracy: 0.4375, time: 1.05 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 057800, loss: 7.4684, train_accuracy: 0.2969, time: 1.15 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 057900, loss: 5.4820, train_accuracy: 0.4219, time: 1.23 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 058000, loss: 4.0699, train_accuracy: 0.4219, time: 1.27 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 058100, loss: 5.7659, train_accuracy: 0.3281, time: 1.28 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 058200, loss: 5.4423, train_accuracy: 0.3281, time: 1.30 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 058300, loss: 6.6917, train_accuracy: 0.3125, time: 1.14 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 058400, loss: 6.5417, train_accuracy: 0.2812, time: 1.21 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 058500, loss: 5.6366, train_accuracy: 0.3594, time: 1.33 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 058600, loss: 6.5455, train_accuracy: 0.3281, time: 1.34 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 058700, loss: 6.0050, train_accuracy: 0.3594, time: 1.37 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 058800, loss: 6.9449, train_accuracy: 0.3281, time: 1.41 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 058900, loss: 7.6309, train_accuracy: 0.3125, time: 1.21 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 059000, loss: 6.8940, train_accuracy: 0.2500, time: 1.16 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 059100, loss: 8.6039, train_accuracy: 0.2344, time: 1.19 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 059200, loss: 5.8157, train_accuracy: 0.3281, time: 1.19 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 059300, loss: 4.7511, train_accuracy: 0.4531, time: 1.39 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 059400, loss: 7.5221, train_accuracy: 0.3594, time: 1.35 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 059500, loss: 6.5890, train_accuracy: 0.3125, time: 1.41 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 059600, loss: 6.4591, train_accuracy: 0.4062, time: 1.33 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 059700, loss: 6.5477, train_accuracy: 0.2344, time: 1.23 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 059800, loss: 7.2701, train_accuracy: 0.3281, time: 1.19 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 059900, loss: 5.7978, train_accuracy: 0.3750, time: 1.20 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 060000, loss: 7.1551, train_accuracy: 0.3438, time: 1.43 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 060100, loss: 4.7277, train_accuracy: 0.4062, time: 1.37 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 060200, loss: 4.7179, train_accuracy: 0.4375, time: 1.38 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 060300, loss: 7.4253, train_accuracy: 0.2500, time: 1.39 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 060400, loss: 6.3586, train_accuracy: 0.3438, time: 1.24 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 060500, loss: 6.7419, train_accuracy: 0.3594, time: 1.15 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 060600, loss: 6.7048, train_accuracy: 0.3125, time: 1.25 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 060700, loss: 7.2480, train_accuracy: 0.3438, time: 1.38 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 060800, loss: 7.6728, train_accuracy: 0.2969, time: 1.36 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 060900, loss: 6.9677, train_accuracy: 0.2500, time: 1.35 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 061000, loss: 6.4890, train_accuracy: 0.3906, time: 1.39 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 061100, loss: 5.1926, train_accuracy: 0.3750, time: 1.20 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 061200, loss: 4.6286, train_accuracy: 0.3594, time: 1.17 s/iter, learning rate: 0.003\n",
      "Epoch 7/11, Iters: 061300, loss: 5.9081, train_accuracy: 0.3906, time: 1.31 s/iter, learning rate: 0.003\n",
      "Epoch 8/11, Iters: 061400, loss: 7.9204, train_accuracy: 0.2969, time: 0.93 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 061500, loss: 8.3524, train_accuracy: 0.2656, time: 1.29 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 061600, loss: 5.7422, train_accuracy: 0.4062, time: 1.29 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 061700, loss: 5.2577, train_accuracy: 0.4062, time: 1.23 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 061800, loss: 5.5100, train_accuracy: 0.3906, time: 1.07 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 061900, loss: 5.9867, train_accuracy: 0.3594, time: 1.04 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 062000, loss: 6.4904, train_accuracy: 0.3906, time: 1.09 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 062100, loss: 6.5705, train_accuracy: 0.2656, time: 1.26 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 062200, loss: 4.2837, train_accuracy: 0.4531, time: 1.29 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 062300, loss: 7.0654, train_accuracy: 0.3438, time: 1.21 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 062400, loss: 5.5886, train_accuracy: 0.4219, time: 1.25 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 062500, loss: 5.2334, train_accuracy: 0.3594, time: 1.23 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 062600, loss: 5.5343, train_accuracy: 0.3906, time: 1.06 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 062700, loss: 5.6630, train_accuracy: 0.4219, time: 1.14 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 062800, loss: 3.8812, train_accuracy: 0.4531, time: 1.27 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 062900, loss: 8.0559, train_accuracy: 0.2812, time: 1.27 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 063000, loss: 5.2230, train_accuracy: 0.4375, time: 1.28 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 063100, loss: 4.9869, train_accuracy: 0.3906, time: 1.30 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 063200, loss: 4.6079, train_accuracy: 0.5156, time: 1.18 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 063300, loss: 5.2724, train_accuracy: 0.4219, time: 1.08 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 063400, loss: 5.7672, train_accuracy: 0.4688, time: 1.09 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 063500, loss: 5.9772, train_accuracy: 0.3281, time: 1.09 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 063600, loss: 4.7615, train_accuracy: 0.4688, time: 1.29 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 063700, loss: 5.8648, train_accuracy: 0.4062, time: 1.24 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 063800, loss: 5.2160, train_accuracy: 0.5469, time: 1.28 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 063900, loss: 5.3647, train_accuracy: 0.4062, time: 1.24 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 064000, loss: 3.8299, train_accuracy: 0.5156, time: 1.23 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 064100, loss: 6.7011, train_accuracy: 0.3594, time: 1.12 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 064200, loss: 7.4429, train_accuracy: 0.2500, time: 1.12 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 064300, loss: 6.0219, train_accuracy: 0.3125, time: 1.17 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 064400, loss: 5.9673, train_accuracy: 0.2969, time: 1.29 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 064500, loss: 6.0291, train_accuracy: 0.2969, time: 1.31 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 064600, loss: 6.7390, train_accuracy: 0.3750, time: 1.30 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 064700, loss: 5.0260, train_accuracy: 0.3750, time: 1.27 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 064800, loss: 7.3797, train_accuracy: 0.4219, time: 1.10 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 064900, loss: 5.4723, train_accuracy: 0.3594, time: 1.10 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 065000, loss: 6.9956, train_accuracy: 0.3750, time: 1.13 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 065100, loss: 6.3264, train_accuracy: 0.3750, time: 1.23 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 065200, loss: 7.3890, train_accuracy: 0.3594, time: 1.28 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 065300, loss: 7.1919, train_accuracy: 0.3125, time: 1.30 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 065400, loss: 6.2792, train_accuracy: 0.3125, time: 1.27 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 065500, loss: 5.9939, train_accuracy: 0.3750, time: 1.22 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 065600, loss: 6.3502, train_accuracy: 0.3750, time: 1.14 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 065700, loss: 6.2716, train_accuracy: 0.2656, time: 1.07 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 065800, loss: 4.6699, train_accuracy: 0.5000, time: 1.26 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 065900, loss: 4.8580, train_accuracy: 0.4219, time: 1.30 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 066000, loss: 6.2030, train_accuracy: 0.3594, time: 1.33 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 066100, loss: 5.3221, train_accuracy: 0.3125, time: 1.37 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 066200, loss: 6.8968, train_accuracy: 0.4219, time: 1.30 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 066300, loss: 7.1585, train_accuracy: 0.3438, time: 1.19 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 066400, loss: 5.8024, train_accuracy: 0.3906, time: 1.22 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 066500, loss: 4.8861, train_accuracy: 0.4844, time: 1.37 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 066600, loss: 5.6359, train_accuracy: 0.3281, time: 1.37 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 066700, loss: 5.0786, train_accuracy: 0.4531, time: 1.34 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 066800, loss: 5.3528, train_accuracy: 0.3438, time: 1.35 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 066900, loss: 5.8503, train_accuracy: 0.3906, time: 1.31 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 067000, loss: 6.3676, train_accuracy: 0.3750, time: 1.15 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 067100, loss: 5.9576, train_accuracy: 0.3750, time: 1.22 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 067200, loss: 5.1951, train_accuracy: 0.4844, time: 1.39 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 067300, loss: 5.9389, train_accuracy: 0.4062, time: 1.38 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 067400, loss: 5.8459, train_accuracy: 0.3594, time: 1.35 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 067500, loss: 5.9860, train_accuracy: 0.4219, time: 1.36 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 067600, loss: 5.5058, train_accuracy: 0.3281, time: 1.26 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 067700, loss: 4.7545, train_accuracy: 0.4375, time: 1.21 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 067800, loss: 5.5911, train_accuracy: 0.3906, time: 1.36 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 067900, loss: 4.8009, train_accuracy: 0.4375, time: 1.34 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 068000, loss: 6.4356, train_accuracy: 0.3281, time: 1.37 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 068100, loss: 5.0387, train_accuracy: 0.4219, time: 1.42 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 068200, loss: 4.7664, train_accuracy: 0.3906, time: 1.31 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 068300, loss: 7.3591, train_accuracy: 0.2500, time: 1.37 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 068400, loss: 7.0510, train_accuracy: 0.3438, time: 1.16 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 068500, loss: 8.5358, train_accuracy: 0.2188, time: 1.23 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 068600, loss: 5.7586, train_accuracy: 0.3438, time: 1.36 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 068700, loss: 4.5830, train_accuracy: 0.4062, time: 1.37 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 068800, loss: 5.5122, train_accuracy: 0.3438, time: 1.39 s/iter, learning rate: 0.0009\n",
      "Epoch 8/11, Iters: 068900, loss: 5.2515, train_accuracy: 0.4531, time: 1.39 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 069000, loss: 5.0604, train_accuracy: 0.4375, time: 0.06 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 069100, loss: 6.2211, train_accuracy: 0.3750, time: 1.14 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 069200, loss: 6.2164, train_accuracy: 0.3438, time: 1.22 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 069300, loss: 5.6227, train_accuracy: 0.4844, time: 1.41 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 069400, loss: 6.2659, train_accuracy: 0.3281, time: 1.33 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 069500, loss: 6.2102, train_accuracy: 0.3594, time: 1.37 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 069600, loss: 5.2788, train_accuracy: 0.4531, time: 1.39 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 069700, loss: 6.6424, train_accuracy: 0.4844, time: 1.20 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 069800, loss: 5.5900, train_accuracy: 0.3750, time: 1.13 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 069900, loss: 6.3949, train_accuracy: 0.3906, time: 1.28 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 070000, loss: 4.9260, train_accuracy: 0.3906, time: 1.33 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 070100, loss: 3.4384, train_accuracy: 0.4844, time: 1.34 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 070200, loss: 5.3186, train_accuracy: 0.4219, time: 1.34 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 070300, loss: 4.5544, train_accuracy: 0.4688, time: 1.29 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 070400, loss: 5.1380, train_accuracy: 0.4062, time: 1.17 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 070500, loss: 4.5141, train_accuracy: 0.4531, time: 1.18 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 070600, loss: 4.6173, train_accuracy: 0.4375, time: 1.19 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 070700, loss: 3.7486, train_accuracy: 0.4531, time: 1.33 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 070800, loss: 4.9816, train_accuracy: 0.4375, time: 1.34 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 070900, loss: 5.0840, train_accuracy: 0.4844, time: 1.32 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 071000, loss: 5.5370, train_accuracy: 0.4062, time: 1.34 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 071100, loss: 6.0185, train_accuracy: 0.4531, time: 1.35 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 071200, loss: 7.6780, train_accuracy: 0.3281, time: 1.37 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 071300, loss: 5.4146, train_accuracy: 0.4219, time: 1.32 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 071400, loss: 4.2613, train_accuracy: 0.5156, time: 1.26 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 071500, loss: 4.7955, train_accuracy: 0.4531, time: 1.16 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 071600, loss: 4.8378, train_accuracy: 0.3906, time: 1.18 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 071700, loss: 6.1691, train_accuracy: 0.3594, time: 1.17 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 071800, loss: 5.2681, train_accuracy: 0.4219, time: 1.19 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 071900, loss: 5.9292, train_accuracy: 0.4062, time: 1.14 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 072000, loss: 4.4595, train_accuracy: 0.4375, time: 1.14 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 072100, loss: 6.3061, train_accuracy: 0.3594, time: 1.35 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 072200, loss: 6.4098, train_accuracy: 0.3281, time: 1.36 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 072300, loss: 5.4877, train_accuracy: 0.4062, time: 1.36 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 072400, loss: 7.6955, train_accuracy: 0.2344, time: 1.37 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 072500, loss: 5.0732, train_accuracy: 0.4219, time: 1.26 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 072600, loss: 5.9582, train_accuracy: 0.3438, time: 1.13 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 072700, loss: 5.2007, train_accuracy: 0.3750, time: 1.29 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 072800, loss: 4.9387, train_accuracy: 0.3906, time: 1.36 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 072900, loss: 4.1812, train_accuracy: 0.4688, time: 1.36 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 073000, loss: 5.4305, train_accuracy: 0.4062, time: 1.25 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 073100, loss: 5.5136, train_accuracy: 0.4375, time: 1.05 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 073200, loss: 5.8916, train_accuracy: 0.3750, time: 1.10 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 073300, loss: 6.1092, train_accuracy: 0.3594, time: 1.13 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 073400, loss: 5.6152, train_accuracy: 0.4062, time: 1.03 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 073500, loss: 7.3424, train_accuracy: 0.3281, time: 1.18 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 073600, loss: 3.9230, train_accuracy: 0.4688, time: 1.31 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 073700, loss: 6.6366, train_accuracy: 0.2812, time: 1.41 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 073800, loss: 7.6784, train_accuracy: 0.2656, time: 1.36 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 073900, loss: 7.9011, train_accuracy: 0.2969, time: 1.36 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 074000, loss: 6.2086, train_accuracy: 0.3750, time: 1.15 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 074100, loss: 6.6133, train_accuracy: 0.3125, time: 1.18 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 074200, loss: 6.3847, train_accuracy: 0.2969, time: 1.23 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 074300, loss: 5.1266, train_accuracy: 0.2656, time: 1.33 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 074400, loss: 6.1164, train_accuracy: 0.2656, time: 1.34 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 074500, loss: 5.3290, train_accuracy: 0.3438, time: 1.42 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 074600, loss: 6.4467, train_accuracy: 0.3750, time: 1.37 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 074700, loss: 5.3515, train_accuracy: 0.4688, time: 1.19 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 074800, loss: 4.9347, train_accuracy: 0.3906, time: 1.23 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 074900, loss: 6.5996, train_accuracy: 0.2969, time: 1.24 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 075000, loss: 5.2441, train_accuracy: 0.4219, time: 1.31 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 075100, loss: 6.5965, train_accuracy: 0.3594, time: 1.29 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 075200, loss: 6.4355, train_accuracy: 0.3281, time: 1.40 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 075300, loss: 5.3454, train_accuracy: 0.3906, time: 1.40 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 075400, loss: 6.8438, train_accuracy: 0.2812, time: 1.36 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 075500, loss: 5.5007, train_accuracy: 0.3438, time: 1.19 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 075600, loss: 5.3176, train_accuracy: 0.4062, time: 1.32 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 075700, loss: 5.8110, train_accuracy: 0.3281, time: 1.35 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 075800, loss: 5.3169, train_accuracy: 0.4062, time: 1.40 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 075900, loss: 5.1300, train_accuracy: 0.4531, time: 1.37 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 076000, loss: 6.8642, train_accuracy: 0.3750, time: 1.28 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 076100, loss: 6.0953, train_accuracy: 0.3125, time: 1.22 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 076200, loss: 5.5559, train_accuracy: 0.4062, time: 1.19 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 076300, loss: 5.0375, train_accuracy: 0.4219, time: 1.32 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 076400, loss: 5.1961, train_accuracy: 0.3594, time: 1.38 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 076500, loss: 5.7017, train_accuracy: 0.4219, time: 1.37 s/iter, learning rate: 0.0009\n",
      "Epoch 9/11, Iters: 076600, loss: 3.5321, train_accuracy: 0.5000, time: 1.40 s/iter, learning rate: 0.0009\n",
      "Epoch 10/11, Iters: 076700, loss: 4.6950, train_accuracy: 0.4062, time: 0.42 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 076800, loss: 5.0309, train_accuracy: 0.5625, time: 1.02 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 076900, loss: 4.1064, train_accuracy: 0.4844, time: 1.06 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 077000, loss: 5.9616, train_accuracy: 0.3594, time: 1.20 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 077100, loss: 5.5540, train_accuracy: 0.5000, time: 1.16 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 077200, loss: 5.2179, train_accuracy: 0.4219, time: 1.21 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 077300, loss: 5.9579, train_accuracy: 0.3906, time: 1.21 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 077400, loss: 4.9449, train_accuracy: 0.4375, time: 1.05 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 077500, loss: 5.8382, train_accuracy: 0.4688, time: 1.00 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 077600, loss: 4.6615, train_accuracy: 0.3906, time: 1.05 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 077700, loss: 6.5783, train_accuracy: 0.3281, time: 0.95 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 077800, loss: 6.4410, train_accuracy: 0.3750, time: 1.07 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 077900, loss: 5.6302, train_accuracy: 0.2969, time: 1.23 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 078000, loss: 7.4058, train_accuracy: 0.3438, time: 1.20 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 078100, loss: 4.7079, train_accuracy: 0.4062, time: 1.12 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 078200, loss: 5.8134, train_accuracy: 0.3906, time: 1.19 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 078300, loss: 6.3070, train_accuracy: 0.3750, time: 0.95 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 078400, loss: 6.0690, train_accuracy: 0.3594, time: 0.88 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 078500, loss: 4.8902, train_accuracy: 0.3281, time: 0.91 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 078600, loss: 6.6508, train_accuracy: 0.3438, time: 0.96 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 078700, loss: 4.8175, train_accuracy: 0.4375, time: 1.03 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 078800, loss: 5.7294, train_accuracy: 0.4375, time: 1.05 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 078900, loss: 5.7208, train_accuracy: 0.3906, time: 1.12 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 079000, loss: 6.2573, train_accuracy: 0.3125, time: 1.15 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 079100, loss: 6.0361, train_accuracy: 0.3438, time: 1.14 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 079200, loss: 4.9849, train_accuracy: 0.3906, time: 1.02 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 079300, loss: 5.1156, train_accuracy: 0.4219, time: 1.01 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 079400, loss: 5.0990, train_accuracy: 0.4688, time: 0.99 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 079500, loss: 5.0031, train_accuracy: 0.4531, time: 1.06 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 079600, loss: 4.6625, train_accuracy: 0.5000, time: 1.12 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 079700, loss: 5.5410, train_accuracy: 0.3438, time: 1.15 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 079800, loss: 5.0799, train_accuracy: 0.3438, time: 1.19 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 079900, loss: 6.9617, train_accuracy: 0.3594, time: 1.14 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 080000, loss: 4.6070, train_accuracy: 0.5312, time: 1.11 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 080100, loss: 3.0898, train_accuracy: 0.5781, time: 0.98 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 080200, loss: 5.8439, train_accuracy: 0.4219, time: 1.03 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 080300, loss: 4.9034, train_accuracy: 0.4062, time: 0.98 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 080400, loss: 6.7565, train_accuracy: 0.4219, time: 1.20 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 080500, loss: 7.6406, train_accuracy: 0.2969, time: 1.13 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 080600, loss: 6.7302, train_accuracy: 0.3750, time: 1.18 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 080700, loss: 5.8772, train_accuracy: 0.2969, time: 1.17 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 080800, loss: 5.7910, train_accuracy: 0.4062, time: 1.18 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 080900, loss: 4.6695, train_accuracy: 0.4219, time: 1.19 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 081000, loss: 5.8697, train_accuracy: 0.3750, time: 1.13 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 081100, loss: 7.4425, train_accuracy: 0.3281, time: 1.15 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 081200, loss: 7.1440, train_accuracy: 0.3125, time: 1.27 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 081300, loss: 6.7763, train_accuracy: 0.2969, time: 1.31 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 081400, loss: 5.9122, train_accuracy: 0.4062, time: 1.37 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 081500, loss: 4.3844, train_accuracy: 0.4219, time: 1.35 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 081600, loss: 6.3008, train_accuracy: 0.3438, time: 1.16 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 081700, loss: 5.1286, train_accuracy: 0.4844, time: 1.15 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 081800, loss: 5.8252, train_accuracy: 0.4219, time: 1.25 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 081900, loss: 5.7471, train_accuracy: 0.4062, time: 1.33 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 082000, loss: 5.6228, train_accuracy: 0.4062, time: 1.34 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 082100, loss: 5.6176, train_accuracy: 0.3906, time: 1.38 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 082200, loss: 6.9295, train_accuracy: 0.2812, time: 1.33 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 082300, loss: 4.9153, train_accuracy: 0.4531, time: 1.17 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 082400, loss: 5.3455, train_accuracy: 0.4062, time: 1.19 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 082500, loss: 5.7596, train_accuracy: 0.4375, time: 1.21 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 082600, loss: 6.0712, train_accuracy: 0.4375, time: 1.36 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 082700, loss: 4.8277, train_accuracy: 0.4531, time: 1.35 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 082800, loss: 6.5001, train_accuracy: 0.3594, time: 1.33 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 082900, loss: 4.8161, train_accuracy: 0.4844, time: 1.34 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 083000, loss: 7.5644, train_accuracy: 0.3750, time: 1.23 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 083100, loss: 7.0943, train_accuracy: 0.3750, time: 1.15 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 083200, loss: 5.3674, train_accuracy: 0.3594, time: 1.33 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 083300, loss: 5.0160, train_accuracy: 0.3906, time: 1.37 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 083400, loss: 6.3875, train_accuracy: 0.4688, time: 1.34 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 083500, loss: 5.7109, train_accuracy: 0.3750, time: 1.33 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 083600, loss: 6.5087, train_accuracy: 0.3281, time: 1.31 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 083700, loss: 3.7716, train_accuracy: 0.4844, time: 1.18 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 083800, loss: 7.2166, train_accuracy: 0.2969, time: 1.13 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 083900, loss: 5.1654, train_accuracy: 0.2969, time: 1.24 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 084000, loss: 6.8432, train_accuracy: 0.2812, time: 1.34 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 084100, loss: 5.5219, train_accuracy: 0.3594, time: 1.39 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 084200, loss: 5.1122, train_accuracy: 0.3438, time: 1.34 s/iter, learning rate: 0.00027\n",
      "Epoch 10/11, Iters: 084300, loss: 4.5525, train_accuracy: 0.4688, time: 1.42 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 084400, loss: 4.6800, train_accuracy: 0.5000, time: 0.76 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 084500, loss: 6.4336, train_accuracy: 0.3750, time: 1.07 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 084600, loss: 3.7508, train_accuracy: 0.5156, time: 1.04 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 084700, loss: 3.9857, train_accuracy: 0.5156, time: 1.07 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 084800, loss: 5.1559, train_accuracy: 0.4062, time: 0.93 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 084900, loss: 4.6724, train_accuracy: 0.4844, time: 0.87 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 085000, loss: 6.3480, train_accuracy: 0.3750, time: 0.94 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 085100, loss: 4.9906, train_accuracy: 0.3281, time: 0.87 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 085200, loss: 7.9202, train_accuracy: 0.3750, time: 0.87 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 085300, loss: 4.3898, train_accuracy: 0.4688, time: 0.94 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 085400, loss: 4.8636, train_accuracy: 0.4844, time: 0.88 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 085500, loss: 5.5447, train_accuracy: 0.3750, time: 0.83 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 085600, loss: 6.2066, train_accuracy: 0.3594, time: 0.93 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 085700, loss: 6.0766, train_accuracy: 0.2656, time: 1.00 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 085800, loss: 5.0587, train_accuracy: 0.5000, time: 1.07 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 085900, loss: 6.2601, train_accuracy: 0.4375, time: 1.00 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 086000, loss: 5.6755, train_accuracy: 0.3125, time: 1.05 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 086100, loss: 7.3019, train_accuracy: 0.3125, time: 1.01 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 086200, loss: 4.7165, train_accuracy: 0.5000, time: 1.02 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 086300, loss: 4.9110, train_accuracy: 0.5156, time: 0.88 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 086400, loss: 6.6338, train_accuracy: 0.3750, time: 0.88 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 086500, loss: 4.2273, train_accuracy: 0.4688, time: 0.94 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 086600, loss: 5.0551, train_accuracy: 0.4375, time: 1.02 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 086700, loss: 6.0644, train_accuracy: 0.3750, time: 1.04 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 086800, loss: 4.6728, train_accuracy: 0.4688, time: 1.00 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 086900, loss: 4.0650, train_accuracy: 0.4688, time: 1.08 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 087000, loss: 6.7142, train_accuracy: 0.3906, time: 1.01 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 087100, loss: 4.8897, train_accuracy: 0.4219, time: 1.04 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 087200, loss: 7.0380, train_accuracy: 0.2969, time: 1.13 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 087300, loss: 4.7034, train_accuracy: 0.4375, time: 1.26 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 087400, loss: 5.0886, train_accuracy: 0.4062, time: 1.34 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 087500, loss: 6.1630, train_accuracy: 0.3906, time: 1.29 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 087600, loss: 5.4471, train_accuracy: 0.4375, time: 1.33 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 087700, loss: 7.2406, train_accuracy: 0.3594, time: 1.37 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 087800, loss: 5.0043, train_accuracy: 0.3750, time: 1.13 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 087900, loss: 4.8481, train_accuracy: 0.4219, time: 1.17 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 088000, loss: 7.7362, train_accuracy: 0.3594, time: 1.19 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 088100, loss: 5.6062, train_accuracy: 0.4531, time: 1.29 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 088200, loss: 4.3219, train_accuracy: 0.4219, time: 1.37 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 088300, loss: 6.8967, train_accuracy: 0.4375, time: 1.40 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 088400, loss: 5.5215, train_accuracy: 0.3750, time: 1.40 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 088500, loss: 6.8411, train_accuracy: 0.3281, time: 1.28 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 088600, loss: 4.4712, train_accuracy: 0.4375, time: 1.17 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 088700, loss: 4.1401, train_accuracy: 0.5312, time: 1.16 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 088800, loss: 6.4032, train_accuracy: 0.4062, time: 1.31 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 088900, loss: 6.6461, train_accuracy: 0.3594, time: 1.34 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 089000, loss: 5.5361, train_accuracy: 0.4219, time: 1.41 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 089100, loss: 4.3104, train_accuracy: 0.4531, time: 1.38 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 089200, loss: 5.5748, train_accuracy: 0.4062, time: 1.31 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 089300, loss: 4.5307, train_accuracy: 0.4062, time: 1.18 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 089400, loss: 6.5195, train_accuracy: 0.4375, time: 1.18 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 089500, loss: 5.4163, train_accuracy: 0.4531, time: 1.32 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 089600, loss: 5.7050, train_accuracy: 0.4062, time: 1.37 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 089700, loss: 6.2848, train_accuracy: 0.3125, time: 1.35 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 089800, loss: 7.6372, train_accuracy: 0.2969, time: 1.36 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 089900, loss: 5.6183, train_accuracy: 0.3906, time: 1.35 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 090000, loss: 5.1620, train_accuracy: 0.3906, time: 1.14 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 090100, loss: 4.2305, train_accuracy: 0.3906, time: 1.15 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 090200, loss: 6.2254, train_accuracy: 0.3438, time: 1.30 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 090300, loss: 7.2481, train_accuracy: 0.4688, time: 1.38 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 090400, loss: 4.7149, train_accuracy: 0.5000, time: 1.43 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 090500, loss: 5.8984, train_accuracy: 0.3594, time: 1.38 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 090600, loss: 6.0820, train_accuracy: 0.3594, time: 1.33 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 090700, loss: 7.1491, train_accuracy: 0.3594, time: 1.15 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 090800, loss: 7.1358, train_accuracy: 0.3594, time: 1.19 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 090900, loss: 5.4926, train_accuracy: 0.4219, time: 1.38 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 091000, loss: 7.0732, train_accuracy: 0.3906, time: 1.42 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 091100, loss: 5.0409, train_accuracy: 0.3906, time: 1.37 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 091200, loss: 5.6383, train_accuracy: 0.4531, time: 1.36 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 091300, loss: 5.0913, train_accuracy: 0.4062, time: 1.25 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 091400, loss: 5.2979, train_accuracy: 0.3281, time: 1.18 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 091500, loss: 6.4961, train_accuracy: 0.3750, time: 1.16 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 091600, loss: 6.8991, train_accuracy: 0.3906, time: 1.39 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 091700, loss: 5.5710, train_accuracy: 0.3750, time: 1.39 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 091800, loss: 5.0769, train_accuracy: 0.5312, time: 1.36 s/iter, learning rate: 0.00027\n",
      "Epoch 11/11, Iters: 091900, loss: 5.2919, train_accuracy: 0.3906, time: 1.40 s/iter, learning rate: 0.00027\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from torch.nn.functional import normalize\n",
    "\n",
    "CASIA_WEBFACE_PATH = \"C:\\\\workspace\\\\facenet\\\\CASIA_webface\\\\\"\n",
    "LATENT_DATA_PATH = \"C:\\\\workspace\\\\facenet\\\\latent_train_data_npy\\\\\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 12\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "dataset_train = LatentData(LATENT_DATA_PATH)\n",
    "net = FaceFeatureExtractor(512).to(device)\n",
    "margin = Arcface(s=32., m=0.5).to(device)\n",
    "\n",
    "dataloader_train = data.DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD([{'params': net.parameters(), 'weight_decay': 5e-4}, {'params': margin.parameters(), 'weight_decay': 5e-4}], lr=0.01, momentum=0.9, nesterov=True)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[6, 8, 10], gamma=0.3)\n",
    "start = time.time()\n",
    "\n",
    "train_logging = 'train_logging.txt'\n",
    "\n",
    "best_acc = 0.\n",
    "best_iters = 0\n",
    "total_iters = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    net.train()\n",
    "    since = time.time()\n",
    "    for det in dataloader_train:\n",
    "        data, label = det[0].to(device), det[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.set_grad_enabled(True):\n",
    "            raw_out = net(data)\n",
    "            logits = torch.nn.functional.normalize(raw_out)\n",
    "            margin_out = margin(logits, label)\n",
    "            loss = criterion(margin_out, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_iters += 1\n",
    "            if total_iters % 100 == 0:\n",
    "                _, preds = torch.max(margin_out.data, 1)\n",
    "                total = label.size(0)\n",
    "                correct = (np.array(preds.cpu()) == np.array(label.data.cpu())).sum()\n",
    "                time_cur = (time.time() - since) / 100\n",
    "                since = time.time()\n",
    "\n",
    "                for p in optimizer.param_groups:\n",
    "                    lr = p['lr']\n",
    "                print(\"Epoch {}/{}, Iters: {:0>6d}, loss: {:.4f}, train_accuracy: {:.4f}, time: {:.2f} s/iter, learning rate: {}\"\n",
    "                          .format(epoch, EPOCHS-1, total_iters, loss.item(), correct/total, time_cur, lr))\n",
    "                with open(train_logging, 'a') as f:\n",
    "                    f.write(\"Epoch {}/{}, Iters: {:0>6d}, loss: {:.4f}, train_accuracy: {:.4f}, time: {:.2f} s/iter, learning rate: {}\"\n",
    "                        .format(epoch, EPOCHS-1, total_iters, loss.item(), correct/total, time_cur, lr)+'\\n')\n",
    "            \n",
    "            if total_iters % 3000 == 0:\n",
    "                torch.save({\n",
    "                    'iters': total_iters,\n",
    "                    'net_state_dict': net.state_dict()},\n",
    "                    'Iter_%06d_model.ckpt' % total_iters)\n",
    "                torch.save({\n",
    "                    'iters': total_iters,\n",
    "                    'net_state_dict': margin.state_dict()},\n",
    "                    'Iter_%06d_margin.ckpt' % total_iters)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'iters': total_iters,\n",
    "    'net_state_dict': net.state_dict()},\n",
    "    'Iter_%06d_model.ckpt' % total_iters)\n",
    "torch.save({\n",
    "    'iters': total_iters,\n",
    "    'net_state_dict': margin.state_dict()},\n",
    "    'Iter_%06d_margin.ckpt' % total_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 128, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "dataset_train[0][0].shape\n",
    "\n",
    "for det in dataloader_train:\n",
    "    data, label = det[0].to(device), det[1].to(device)\n",
    "    print(data.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.onnx\n",
    "\n",
    "dummpy_input = torch.randn(1, 128, 7, 7)\n",
    "\n",
    "torch.onnx.export(net, dummpy_input, \"facenet.onnx\", export_params=True, opset_version=14, do_constant_folding=True,\n",
    "    input_names=[\"input\"], output_names=[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b081a66ee97bd2b6a16f43955f1d810b7ea816d6eaeb65e157ef9e038445f0c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
